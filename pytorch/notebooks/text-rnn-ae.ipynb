{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text RNN Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "home_dir = os.path.expanduser('~')\n",
    "sys.path.append(\"{}/dev/github/ml-toolkit\".format(home_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch.utils.data.text.vectorizer import Vectorizer\n",
    "\n",
    "vectorizer = Vectorizer(default_indexes={0: '<pad>', 1: '<unk>', 2: '<sos>', 3: '<eos>'})\n",
    "vectorizer.load_dictionary('{}/data/datasets/hotel-reviews-txt/dictionary'.format(home_dir), word_col=0)\n",
    "\n",
    "print(vectorizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq_list = []\n",
    "with open('{}/data/datasets/hotel-reviews-txt/train_permute.txt'.format(home_dir)) as infile:\n",
    "    for idx, line in enumerate(infile):\n",
    "        seq = [ int(i) for i in line.strip().split()]\n",
    "        train_seq_list.append(seq)\n",
    "\n",
    "X, indices, lengths = vectorizer.prepare_sequences(train_seq_list, auto_padding=False, max_len=50, unknown_idx=1, return_lengths=True)\n",
    "\n",
    "# Free up some memory\n",
    "train_seq_list = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "seq = X[idx]\n",
    "seq_decoded = vectorizer.sequence_to_text(seq)\n",
    "print(seq_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get max index (parameter for embedding layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = int(np.max([ np.max(seq) for seq in X ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample dataset for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "X_train = X[:num_samples]\n",
    "\n",
    "print(\"Size of training set: {}\".format(len(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch.utils.data.text.wordvectorloader import WordVectorLoader\n",
    "\n",
    "use_pretrained_embeddings = False\n",
    "\n",
    "if use_pretrained_embeddings is True:\n",
    "    word_vector_loader = WordVectorLoader(300)\n",
    "    embed_mat = word_vector_loader.create_embedding_matrix('{}/data/dumps/glove/glove.840B.300d.txt'.format(home_dir), vectorizer.vocabulary.word_to_index, max_idx, init='random', verbatim=True)\n",
    "    print(embed_mat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training data iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch.utils.data.text.dataset import BucketBatchSampler, BucketDataset\n",
    "\n",
    "bucket_batch_sampler = BucketBatchSampler(X_train, batch_size)\n",
    "bucket_dataset = BucketDataset(X_train, None)\n",
    "\n",
    "X_train_iter = DataLoader(bucket_dataset, batch_size=1, batch_sampler=bucket_batch_sampler, shuffle=False, num_workers=8, drop_last=False)\n",
    "\n",
    "print(len(X_train_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch.models.text.autoencoder.textrnnae import RnnType, Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '{}/data/ml-toolkit/pytorch-models/text-rnn-ae/'.format(home_dir)\n",
    "\n",
    "params = { 'rnn_type': RnnType.LSTM,\n",
    "           'rnn_hidden_dim': 512,\n",
    "           'num_layers': 1,\n",
    "           'bidirectional_encoder': True,\n",
    "           'dropout': 0.0,\n",
    "           'vocab_size': max_idx+1,\n",
    "           'embed_dim': 300,\n",
    "           'clip': 0.5,\n",
    "           'encoder_lr': 0.001,\n",
    "           'decoder_lr': 0.001,\n",
    "           'teacher_forcing_prob': 0.0,\n",
    "           'linear_dims': [],\n",
    "           'z_dim': 1024 }\n",
    "\n",
    "print(params)\n",
    "with open(path+'params.json', 'w') as outfile:\n",
    "    json.dump(params, outfile)\n",
    "\n",
    "params = Parameters(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch.models.text.autoencoder.textrnnae import TextRnnAE\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "text_rnn_ae = TextRnnAE(device, params, criterion)\n",
    "\n",
    "print(text_rnn_ae.encoder)\n",
    "print(text_rnn_ae.decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set pretrained word embeddings if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_pretrained_embeddings is True:\n",
    "    text_rnn_ae.embedding.weight.data.copy_(torch.from_numpy(embed_mat))\n",
    "    text_rnn_ae.embedding.weight.requires_grad=False\n",
    "else:\n",
    "    text_rnn_ae.embedding.weight.requires_grad=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "safe_after_epoch = False\n",
    "\n",
    "encoder_file_name = '{}/data/ml-toolkit/pytorch-models/text-rnn-ae/textrnnae-encoder.model'.format(home_dir)\n",
    "decoder_file_name = '{}/data/ml-toolkit/pytorch-models/text-rnn-ae/textrnnae-decoder.model'.format(home_dir)\n",
    "\n",
    "\n",
    "text_rnn_ae.train()\n",
    "\n",
    "#text_rnn_ae.set_learning_rates(0.001, 0.001)\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = text_rnn_ae.train_epoch(epoch, X_train_iter, verbatim=True)\n",
    "    print(epoch_loss)\n",
    "    losses.append(epoch_loss)\n",
    "    if safe_after_epoch:\n",
    "        text_rnn_ae.save_models(encoder_file_name, decoder_file_name)\n",
    "    text_rnn_ae.update_learning_rates(0.99, 0.99)\n",
    "        \n",
    "text_rnn_ae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_loss = np.max(losses)\n",
    "losses_normalized = losses / max_loss\n",
    "\n",
    "plt.plot(losses_normalized, label='loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('RNN-AE (e_dim={}, h_dim={})'.format(params.embed_dim, params.rnn_hidden_dim))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sequence(sequence, model, vectorizer, max_length=100):\n",
    "    original_sequence = vectorizer.sequence_to_text(sequence)\n",
    "    X = torch.tensor([sequence], dtype=torch.long).to(model.device)\n",
    "    decoded_indices = model.evaluate(X)\n",
    "    decoded_sequence = vectorizer.sequence_to_text(decoded_indices)\n",
    "    return ' '.join(original_sequence), ' '.join(decoded_sequence)\n",
    "    \n",
    "print(check_sequence(X_train[0], text_rnn_ae, vectorizer, max_length=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check a sample of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, s in enumerate(X_train):\n",
    "    original, decoded = check_sequence(s, text_rnn_ae, vectorizer)\n",
    "    print(\"================================================\")\n",
    "    print()\n",
    "    print(original)\n",
    "    print(\">>>\")\n",
    "    print(decoded)\n",
    "    print()\n",
    "    if idx > 200:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
