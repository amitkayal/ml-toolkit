{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BucketBatchSampler Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "home_dir = os.path.expanduser('~')\n",
    "sys.path.append(\"{}/dev/github/ml-toolkit\".format(home_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data items: 22\n"
     ]
    }
   ],
   "source": [
    "data = [('one two three four', 'eins zwei drei vier'),\n",
    "        ('one two three four', 'eins zwei drei vier'),\n",
    "        ('one two three four', 'eins zwei drei vier'),\n",
    "        ('one two three four', 'eins zwei drei vier'),\n",
    "        ('one two three four', 'eins zwei drei vier'),\n",
    "        ('one two three four', 'eins zwei drei vier'),\n",
    "        ('one two three four', 'eins zwei drei'),\n",
    "        ('one two three four', 'eins zwei drei'),\n",
    "        ('one two three four', 'eins zwei drei'),\n",
    "        ('one two three four', 'eins zwei drei vier fuenf'),\n",
    "        ('one two three four', 'eins zwei drei vier fuenf'),\n",
    "        ('one two three', 'eins zwei drei vier'),\n",
    "        ('one two three', 'eins zwei drei'),\n",
    "        ('one two three', 'eins zwei drei'),\n",
    "        ('one two three', 'eins zwei drei'),\n",
    "        ('one two three', 'eins zwei drei'),\n",
    "        ('one two three', 'eins zwei drei'),\n",
    "        ('one two three', 'eins zwei drei'),\n",
    "        ('one two three', 'eins zwei drei'),\n",
    "        ('one two three', 'eins zwei drei'),\n",
    "        ('one two three', 'eins zwei drei'),\n",
    "        ('one two three', 'eins zwei drei vier fuenf')\n",
    "       ]\n",
    "\n",
    "print(\"Number of data items: {}\".format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [ tup[0] for tup in data ]\n",
    "targets = [ tup[1] for tup in data ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize Data\n",
    "\n",
    "**IMPORTANT:** For a traditional machine translation tasks with two different vocabularies, one should use two vectorizers, one for each language. Here it doesn't matter, since we're only interested in the shape of the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch.utils.data.text.vectorizer import Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'one': 0, 'two': 1, 'three': 2, 'eins': 3, 'zwei': 4, 'drei': 5, 'four': 6, 'vier': 7, 'fuenf': 8}\n"
     ]
    }
   ],
   "source": [
    "# Method fit_on_texts expects a list of strings, so we need to merge the tuples forist\n",
    "text_list = [ \"{} {}\".format(tup[0], tup[1]) for tup in data ]\n",
    "\n",
    "vectorizer = Vectorizer()\n",
    "vectorizer.fit_on_texts(text_list)\n",
    "\n",
    "print(vectorizer.vocabulary.word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 1, 2, 6]) array([0, 1, 2, 6]) array([0, 1, 2, 6])\n",
      " array([0, 1, 2, 6]) array([0, 1, 2, 6]) array([0, 1, 2, 6])\n",
      " array([0, 1, 2, 6]) array([0, 1, 2, 6]) array([0, 1, 2, 6])\n",
      " array([0, 1, 2, 6]) array([0, 1, 2, 6]) array([0, 1, 2]) array([0, 1, 2])\n",
      " array([0, 1, 2]) array([0, 1, 2]) array([0, 1, 2]) array([0, 1, 2])\n",
      " array([0, 1, 2]) array([0, 1, 2]) array([0, 1, 2]) array([0, 1, 2])\n",
      " array([0, 1, 2])]\n"
     ]
    }
   ],
   "source": [
    "inputs_vectorized, _ = vectorizer.texts_to_sequences(inputs)\n",
    "targets_vectorized, _ = vectorizer.texts_to_sequences(targets)\n",
    "\n",
    "print(inputs_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 8\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from pytorch.utils.data.text.dataset import BucketBatchSampler, BucketDataset\n",
    "\n",
    "bucket_batch_sampler = BucketBatchSampler(batch_size, inputs_vectorized, targets_vectorized)\n",
    "# In case targets=None    \n",
    "#bucket_batch_sampler = BucketBatchSampler(batch_size, inputs_vectorized, None)\n",
    "\n",
    "bucket_dataset = BucketDataset(inputs_vectorized, targets_vectorized)\n",
    "# In case targets=None    \n",
    "#bucket_dataset = BucketDataset(inputs_vectorized, None)\n",
    "\n",
    "data_iter = DataLoader(bucket_dataset,batch_sampler=bucket_batch_sampler, shuffle=False, num_workers=6, drop_last=False)\n",
    "\n",
    "print(\"Number of batches: {}\".format(data_iter.batch_sampler.batch_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++\n",
      "tensor([[0, 1, 2, 6],\n",
      "        [0, 1, 2, 6],\n",
      "        [0, 1, 2, 6],\n",
      "        [0, 1, 2, 6],\n",
      "        [0, 1, 2, 6]])\n",
      "tensor([[3, 4, 5, 7],\n",
      "        [3, 4, 5, 7],\n",
      "        [3, 4, 5, 7],\n",
      "        [3, 4, 5, 7],\n",
      "        [3, 4, 5, 7]])\n",
      "++++++++++++++++++++\n",
      "tensor([[0, 1, 2],\n",
      "        [0, 1, 2],\n",
      "        [0, 1, 2],\n",
      "        [0, 1, 2],\n",
      "        [0, 1, 2]])\n",
      "tensor([[3, 4, 5],\n",
      "        [3, 4, 5],\n",
      "        [3, 4, 5],\n",
      "        [3, 4, 5],\n",
      "        [3, 4, 5]])\n",
      "++++++++++++++++++++\n",
      "tensor([[0, 1, 2]])\n",
      "tensor([[3, 4, 5, 7, 8]])\n",
      "++++++++++++++++++++\n",
      "tensor([[0, 1, 2, 6]])\n",
      "tensor([[3, 4, 5, 7]])\n",
      "++++++++++++++++++++\n",
      "tensor([[0, 1, 2, 6],\n",
      "        [0, 1, 2, 6],\n",
      "        [0, 1, 2, 6]])\n",
      "tensor([[3, 4, 5],\n",
      "        [3, 4, 5],\n",
      "        [3, 4, 5]])\n",
      "++++++++++++++++++++\n",
      "tensor([[0, 1, 2],\n",
      "        [0, 1, 2],\n",
      "        [0, 1, 2],\n",
      "        [0, 1, 2]])\n",
      "tensor([[3, 4, 5],\n",
      "        [3, 4, 5],\n",
      "        [3, 4, 5],\n",
      "        [3, 4, 5]])\n",
      "++++++++++++++++++++\n",
      "tensor([[0, 1, 2, 6],\n",
      "        [0, 1, 2, 6]])\n",
      "tensor([[3, 4, 5, 7, 8],\n",
      "        [3, 4, 5, 7, 8]])\n",
      "++++++++++++++++++++\n",
      "tensor([[0, 1, 2]])\n",
      "tensor([[3, 4, 5, 7]])\n"
     ]
    }
   ],
   "source": [
    "for batch_inputs, batch_targets in data_iter:\n",
    "    print(\"++++++++++++++++++++\")\n",
    "    print(batch_inputs)\n",
    "    print(batch_targets)\n",
    "    \n",
    "# In case targets=None    \n",
    "#for batch_inputs in data_iter:\n",
    "#    print(\"++++++++++++++++++++\")\n",
    "#    print(batch_inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Example\n",
    "\n",
    "Link to dataset: http://www.isi.edu/natural-language/download/hansard/hansard.36.r2001-1a.house.debates.training.tar\n",
    "\n",
    "(for the test, I considered only the first 1 Million lines in each file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fa53dbfdd30>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vdw/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/vdw/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/vdw/env/anaconda3/envs/py36/lib/python3.6/multiprocessing/process.py\", line 124, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/vdw/env/anaconda3/envs/py36/lib/python3.6/multiprocessing/popen_fork.py\", line 50, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/home/vdw/env/anaconda3/envs/py36/lib/python3.6/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000 done\n",
      "1000000\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "cnt = 0\n",
    "with open(\"train.de.sample\") as f1, open(\"train.en.sample\") as f2: \n",
    "    for x, y in zip(f1, f2):\n",
    "        x = x.strip()\n",
    "        y = y.strip()\n",
    "        #print(\"{0}\\t{1}\".format(x, y))\n",
    "        data.append((x, y))\n",
    "        cnt += 1\n",
    "        if cnt % 1000000 == 0:\n",
    "            print(\"{} done\".format(cnt))\n",
    "        \n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iron cement ist eine gebrauchs ##AT##-##AT## fertige Paste , die mit einem Spachtel oder den Fingern als Hohlkehle in die Formecken ( Winkel ) der Stahlguss -Kokille aufgetragen wird .', 'iron cement is a ready for use paste which is laid as a fillet by putty knife or finger in the mould edges ( corners ) of the steel ingot mould .')\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize Data\n",
    "\n",
    "**IMPORTANT:** For a traditional machine translation tasks with two different vocabularies, one should use two vectorizers, one for each language. Here it doesn't matter, since we're only interested in the shape of the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch.utils.data.text.vectorizer import Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method fit_on_texts expects a list of strings, so we need to merge the tuples forist\n",
    "text_list = [ \"{} {}\".format(tup[0], tup[1]) for tup in data ]\n",
    "\n",
    "# In a real setting, you typically want to reserve some default tokens\n",
    "vectorizer = Vectorizer(default_indexes={0: '<pad>', 1: '<unk>', 2: '<sos>', 3: '<eos>'})\n",
    "vectorizer.fit_on_texts(text_list)\n",
    "\n",
    "# We don't need this anyore => make some room in the memory\n",
    "text_list = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([  5651,  25122,     29,     44, 486259,     11,  28715,  26681,\n",
      "            4,     15,     25,     87, 172118,     55,     28,  40513,\n",
      "           73, 486260,      7,     15, 486261,     17,  16130,     18,\n",
      "           13, 262353, 486262,  43090,     76,      5])\n",
      " array([   588,     13, 322259,  10322,   5651,  25122,     15, 262354,\n",
      "          450,     28,  23841,      4, 262355, 262353,      5])\n",
      " array([262356, 486263,     35, 486264,      4,  59463,      4,   7832,\n",
      "       144743,   1560])\n",
      " ...\n",
      " array([  2223,    187,    299,     41,  12492,     32,      6,   1369,\n",
      "           12,  21886,     14,   3109,   1237,      9,    187,   3997,\n",
      "          413,   1599,     27,    191, 486258,   3327,    456,     21,\n",
      "         5009,   1390,   6894,      5])\n",
      " array([ 9368, 15797,   371, 10130,   452,  1358, 74060,    14,   691,\n",
      "        8271,   371, 10130, 12492, 19053,   165,  2722,    79,  8081,\n",
      "        1191, 26575,  9332, 19923,    79,  1786,   413,  1599,  2146,\n",
      "         122,  3424,     4,  7937,     4,  1278,     4, 37507,     4,\n",
      "       10716,   350,   452, 13467,    79,  8450,   413,  1599,     5])\n",
      " array([ 9368,   930,   313, 38613,    79,   165,  1390,    14,   691,\n",
      "         299,   371,   313, 12492, 19053,   165,  2722,    79,  8081,\n",
      "        1422, 18916,  5042,   531, 26024,  1735,   452, 66339,    79,\n",
      "       35927,   350,  9155,     4,   145,  3424,  2146, 25156, 15895,\n",
      "          79, 15426, 75421,     4,   452,  4771,  7937,     4,  1278,\n",
      "           4,  6525,   531, 60071,     4,  5909,     4, 10606,   350,\n",
      "         452,    64])]\n",
      "1000000\n"
     ]
    }
   ],
   "source": [
    "inputs = [ tup[0] for tup in data ]\n",
    "targets = [ tup[1] for tup in data ]\n",
    "\n",
    "inputs_vectorized, _ = vectorizer.texts_to_sequences(inputs, padding_idx=0, unknown_idx=1)\n",
    "targets_vectorized, _ = vectorizer.texts_to_sequences(targets, padding_idx=0, unknown_idx=1)\n",
    "\n",
    "print(inputs_vectorized)\n",
    "print(len(inputs_vectorized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 36705\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from pytorch.utils.data.text.dataset import BucketBatchSampler, BucketDataset\n",
    "\n",
    "bucket_batch_sampler = BucketBatchSampler(batch_size, inputs_vectorized, targets_vectorized)\n",
    "\n",
    "bucket_dataset = BucketDataset(inputs_vectorized, targets_vectorized)\n",
    "\n",
    "data_iter = DataLoader(bucket_dataset,batch_sampler=bucket_batch_sampler, shuffle=False, num_workers=6, drop_last=False)\n",
    "\n",
    "print(\"Number of batches: {}\".format(data_iter.batch_sampler.batch_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "print(len(bucket_batch_sampler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = {}\n",
    "\n",
    "for batch_input, batch_target in data_iter:\n",
    "    batch_size = batch_input.shape[0]\n",
    "    if batch_size in batch_sizes:\n",
    "        batch_sizes[batch_size] += 1\n",
    "    else:\n",
    "        batch_sizes[batch_size] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "lists = sorted(batch_sizes.items()) # sorted by key, return a list of tuples\n",
    "\n",
    "x, y = zip(*lists) # unpack a list of pairs into two tuples\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.savefig('bucketbatchsample-batch-size-distribution.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
